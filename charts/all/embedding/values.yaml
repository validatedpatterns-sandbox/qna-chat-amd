global: 
  pattern: amdllm

  amdllm:
    namespace: amd-llm
    build_envs: [] # http_proxy/https_prxy can be set here
    runtime_envs: []

    service_name: embedding
    service_port: 5002
    container_port: 6000
    route_path: /v1/embeddings
    docker_file_Path: comps/embeddings/src/Dockerfile

    image:
      pre_built: quay.io/sgahlot/opea/embedding:latest
      from_source: image-registry.openshift-image-registry.svc:5000/opea/embedding:latest

    git_repo_uri: https://github.com/opea-project/GenAIComps.git
    git_ref: 3e559df   # make sure to validate buildconfig & other change scope before updating

    tei_service:
      name: tei-embedding-service
      port: 5007
      env_var_name: TEI_EMBEDDING_ENDPOINT

    build:
      enable: false

    env:
      - name: HOME
        value: /tmp/temp-data
      - name: PYTHONPATH
        value: /home/user/.local/lib/python3.11/site-packages:/home/user:/home

    volume:
      - name: temp-data
        path: /tmp/temp-data
